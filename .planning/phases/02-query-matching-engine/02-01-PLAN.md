---
phase: 02-query-matching-engine
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - Cargo.toml
  - src/main.rs
  - src/matcher/mod.rs
  - src/matcher/error.rs
  - src/matcher/config.rs
  - src/matcher/normalize.rs
autonomous: true

must_haves:
  truths:
    - "MatchConfig loads MATCH_THRESHOLD, MATCH_FUZZY_WEIGHT, MATCH_KEYWORD_WEIGHT from environment with sensible defaults"
    - "MatchConfig validates threshold in [0.0, 1.0] and weights sum to 1.0"
    - "normalize_text lowercases, strips punctuation, removes stop words, normalizes whitespace in that order"
    - "Empty query returns MatchError::EmptyQuery"
    - "All-stop-words query returns MatchError::QueryAllStopWords"
    - "MatchError::BelowThreshold includes closest_slug, closest_score, all_slugs, and GitHub link"
  artifacts:
    - path: "src/matcher/mod.rs"
      provides: "Module re-exports for matcher subsystem"
    - path: "src/matcher/error.rs"
      provides: "MatchError enum with EmptyQuery, QueryAllStopWords, BelowThreshold variants"
      contains: "MatchError"
    - path: "src/matcher/config.rs"
      provides: "MatchConfig struct with envy deserialization and validation"
      contains: "MatchConfig"
    - path: "src/matcher/normalize.rs"
      provides: "normalize_text function implementing 4-stage normalization pipeline"
      exports: ["normalize_text"]
  key_links:
    - from: "src/matcher/config.rs"
      to: "envy"
      via: "envy::from_env deserialization"
      pattern: "envy::from_env"
    - from: "src/matcher/normalize.rs"
      to: "stop_words"
      via: "stop_words::get(LANGUAGE::English)"
      pattern: "stop_words::get"
    - from: "src/main.rs"
      to: "src/matcher/mod.rs"
      via: "mod matcher declaration"
      pattern: "mod matcher"
---

<objective>
Create the matcher module foundation: dependencies, configuration, error types, and text normalization pipeline.

Purpose: Establishes the module structure and normalization layer that the scoring engine (Plan 02) builds on. Normalization is the first half of the normalize-score-select pipeline.
Output: Working matcher module with MatchConfig, MatchError, and normalize_text() that passes unit tests.
</objective>

<execution_context>
@/home/john/.claude/get-shit-done/workflows/execute-plan.md
@/home/john/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-query-matching-engine/02-CONTEXT.md
@.planning/phases/02-query-matching-engine/02-RESEARCH.md
@src/registry/types.rs
@src/config.rs
@src/main.rs
@Cargo.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add dependencies and create matcher module structure</name>
  <files>
    Cargo.toml
    src/main.rs
    src/matcher/mod.rs
    src/matcher/error.rs
    src/matcher/config.rs
  </files>
  <action>
    1. Add dependencies to Cargo.toml:
       - `strsim = "0.11.1"` under [dependencies]
       - `stop-words = { version = "0.9.0", features = ["iso", "nltk"] }` under [dependencies]
       - `approx = "0.5"` under [dev-dependencies] section (create section if needed)

    2. Create `src/matcher/error.rs` with MatchError enum (thiserror):
       - `EmptyQuery` — "Query cannot be empty"
       - `QueryAllStopWords` — "Query contains only stop words and has no searchable content"
       - `BelowThreshold` with fields: threshold (f64), closest_slug (String), closest_score (f64), all_slugs (Vec<String>)
         Error message format: "No category matches query (threshold: {threshold:.2}). Closest: {closest_slug} ({closest_score:.2}). Available: {all_slugs:?}. Request a new category at https://github.com/johnzilla/3goodsources"

    3. Create `src/matcher/config.rs` with MatchConfig struct:
       - `match_threshold: f64` with default 0.4
       - `match_fuzzy_weight: f64` with default 0.7
       - `match_keyword_weight: f64` with default 0.3
       - Use `#[derive(Debug, Deserialize)]` and `#[serde(default)]` field defaults (same pattern as src/config.rs)
       - `MatchConfig::load()` method using `envy::from_env::<MatchConfig>()` — note: this deserializes ONLY the MATCH_* env vars because envy ignores unrecognized fields
       - `MatchConfig::validate()` method: threshold must be in [0.0, 1.0], weights must sum to approximately 1.0 (use (weights_sum - 1.0).abs() > 0.01)
       - Do NOT merge into existing Config struct. Keep separate — matching config is a separate concern.

    4. Create `src/matcher/mod.rs`:
       - Declare submodules: `pub mod config;`, `pub mod error;`, `pub mod normalize;` (normalize added in Task 2, but declare it now)
       - Re-export key types: `pub use config::MatchConfig;`, `pub use error::MatchError;`
       - Do NOT declare `pub mod scorer;` yet — that's Plan 02

    5. Wire into application:
       - Add `mod matcher;` to `src/main.rs` (after existing mod declarations)
       - In main(), after Config::load(), add: `let match_config = matcher::MatchConfig::load()?;` then `match_config.validate()?;`
       - Add tracing::info! log for match config loaded (threshold, weights)
  </action>
  <verify>
    Run `cargo check` — project compiles with new dependencies and module structure.
    Run `cargo test` — no test failures (no tests yet, but compilation check).
  </verify>
  <done>
    - Cargo.toml has strsim 0.11.1, stop-words 0.9.0 with features, approx 0.5 dev-dep
    - MatchError has 3 variants matching CONTEXT.md spec
    - MatchConfig loads from env vars with correct defaults (0.4, 0.7, 0.3)
    - MatchConfig validates threshold range and weight sum
    - matcher module is declared in main.rs and config loads at startup
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement text normalization pipeline with tests</name>
  <files>
    src/matcher/normalize.rs
  </files>
  <action>
    Create `src/matcher/normalize.rs` implementing the 4-stage normalization pipeline:

    1. Public function signature: `pub fn normalize_text(text: &str) -> Result<String, MatchError>`

    2. Pre-check: If `text.trim().is_empty()`, return `Err(MatchError::EmptyQuery)`

    3. Stage 1 — Lowercase: `text.to_lowercase()`

    4. Stage 2 — Strip punctuation: Use `regex::Regex::new(r"[^\w\s]")` to remove all characters that are not word characters or whitespace. This turns "don't" into "dont", removes commas, periods, question marks, etc.

    5. Stage 3 — Remove stop words: Use `stop_words::get(stop_words::LANGUAGE::English)` to get the NLTK English stop word list (~127 words). Collect into HashSet<String> for O(1) lookup. Split normalized text by whitespace, filter out words present in stop word set, rejoin with single space.

    6. Stage 4 — Normalize whitespace: Use `regex::Regex::new(r"\s+")` to collapse multiple spaces. Trim leading/trailing whitespace.

    7. Post-check: If result is empty after all stages, return `Err(MatchError::QueryAllStopWords)`

    8. Performance note: The Regex objects and stop word HashSet are created each call. For ~10 categories this is fine. Do NOT use lazy_static or OnceLock — premature optimization.

    9. Add unit tests in `#[cfg(test)] mod tests` at bottom of file:
       - `test_basic_normalization`: "Learn Rust Programming" -> "learn rust programming"
       - `test_punctuation_removal`: "don't panic! it's fine." -> should remove punctuation, then stop words
       - `test_stop_word_removal`: "how do I run a bitcoin node" -> "run bitcoin node"
       - `test_whitespace_normalization`: "  too   many    spaces  " -> normalized to single spaces
       - `test_empty_query`: "" -> Err(EmptyQuery)
       - `test_whitespace_only_query`: "   " -> Err(EmptyQuery)
       - `test_all_stop_words`: "the a an" -> Err(QueryAllStopWords)
       - `test_mixed_case_and_punctuation`: "What's the BEST way?" -> removes stop words and punctuation, lowercases
       - `test_preserves_content_words`: "bitcoin node setup guide" -> keeps meaningful words (bitcoin, node, setup, guide — none are stop words)
  </action>
  <verify>
    Run `cargo test --lib matcher::normalize` — all normalization tests pass.
    Run `cargo check` — no warnings.
  </verify>
  <done>
    - normalize_text implements lowercase -> strip punctuation -> remove stop words -> normalize whitespace in that exact order
    - Empty input returns MatchError::EmptyQuery
    - All-stop-words input returns MatchError::QueryAllStopWords
    - All 9+ unit tests pass
    - "how do I run a bitcoin node" normalizes to "run bitcoin node"
  </done>
</task>

</tasks>

<verification>
1. `cargo check` passes with no errors
2. `cargo test` passes with all normalize tests green
3. Application starts successfully: `REGISTRY_PATH=registry.json cargo run` shows match config loaded log
4. MatchConfig defaults are correct when no MATCH_* env vars set (threshold=0.4, fuzzy=0.7, keyword=0.3)
</verification>

<success_criteria>
- matcher module exists with config, error, and normalize submodules
- MatchConfig loads from environment with validation
- normalize_text pipeline handles all edge cases (empty, stop words, punctuation, whitespace)
- All unit tests pass
- Project compiles and runs
</success_criteria>

<output>
After completion, create `.planning/phases/02-query-matching-engine/02-01-SUMMARY.md`
</output>
