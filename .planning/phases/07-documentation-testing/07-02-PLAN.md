---
phase: 07-documentation-testing
plan: 02
type: execute
wave: 1
depends_on: []
files_modified: [docs/SCHEMA.md, docs/METHODOLOGY.md, docs/PUBKY.md]
autonomous: true

must_haves:
  truths:
    - "docs/SCHEMA.md documents every field in registry.json with types and constraints"
    - "docs/METHODOLOGY.md explains source curation criteria with worked example"
    - "docs/METHODOLOGY.md documents the query matching algorithm"
    - "docs/PUBKY.md explains PKARR verification with step-by-step curl commands"
    - "docs/PUBKY.md describes future federated vision and endorsements"
  artifacts:
    - path: "docs/SCHEMA.md"
      provides: "Complete registry.json format documentation"
      min_lines: 80
    - path: "docs/METHODOLOGY.md"
      provides: "Source curation criteria and matching algorithm documentation"
      min_lines: 120
    - path: "docs/PUBKY.md"
      provides: "PKARR identity and verification documentation"
      min_lines: 80
  key_links:
    - from: "docs/SCHEMA.md"
      to: "src/registry/types.rs"
      via: "documents the types defined in"
      pattern: "Registry|Category|Source|Curator"
    - from: "docs/METHODOLOGY.md"
      to: "src/matcher/scorer.rs"
      via: "documents the algorithm implemented in"
      pattern: "Levenshtein|keyword|threshold"
---

<objective>
Create three deep-dive documentation files covering registry schema, source curation methodology, and PKARR identity/verification.

Purpose: These docs provide transparency (how sources are chosen), technical reference (registry format), and verification guidance (proving curator identity). They complement README.md by going deep where README stays high-level.

Output: docs/SCHEMA.md, docs/METHODOLOGY.md, docs/PUBKY.md
</objective>

<execution_context>
@/home/john/.claude/get-shit-done/workflows/execute-plan.md
@/home/john/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@src/registry/types.rs
@src/registry/loader.rs
@src/matcher/scorer.rs
@src/matcher/normalize.rs
@src/matcher/config.rs
@src/pubky/identity.rs
@src/mcp/tools.rs
@registry.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Write docs/SCHEMA.md</name>
  <files>docs/SCHEMA.md</files>
  <action>
Create docs/SCHEMA.md documenting the registry.json format completely.

**Title:** `# Registry Schema (registry.json)`

**Overview:** Brief explanation of what registry.json is, its role as the single source of truth for curated sources.

**Top-Level Structure:** Document with JSON example:
- `version` (string): Semver version, e.g. "0.1.0"
- `updated` (string): ISO 8601 date, e.g. "2026-02-01"
- `curator` (object): Curator identity
- `endorsements` (array): Endorsement objects (empty in v1)
- `categories` (object): HashMap keyed by slug

**Curator Object:**
- `name` (string): Display name
- `pubkey` (string): PKARR public key (z-base-32 encoded)

**Category Object:** Document each field:
- `name` (string): Human-readable category name
- `description` (string): What this category covers
- `query_patterns` (array of strings): Natural language patterns for matching (minimum 3)
- `sources` (array of Source): Exactly 3 curated sources

**Source Object:**
- `rank` (integer 1-3): Priority ranking
- `name` (string): Source display name
- `url` (string): Source URL
- `type` (string enum): One of: documentation, tutorial, video, article, tool, repo, forum, book, course, api
- `why` (string): Curator's explanation of why this source is valuable

**Validation Rules section:**
- Slugs must match `^[a-z0-9]+(-[a-z0-9]+)*$`
- Each category must have exactly 3 sources
- Source ranks must be sequential 1, 2, 3
- Minimum 3 query patterns per category
- `#[serde(deny_unknown_fields)]` rejects unknown fields

**Full Example:** Include a complete single-category example from actual registry.json (e.g., rust-learning).

Note: docs/ directory already has index.html and CNAME -- just add SCHEMA.md alongside them.
  </action>
  <verify>
- `test -f docs/SCHEMA.md && echo "exists"`
- `grep "version\|curator\|categories\|sources\|rank" docs/SCHEMA.md` confirms all fields documented
- `grep "deny_unknown_fields\|exactly 3" docs/SCHEMA.md` confirms validation rules
- `wc -l docs/SCHEMA.md` shows 80+ lines
  </verify>
  <done>
docs/SCHEMA.md documents every field in registry.json with types, constraints, validation rules, and a real example from seed data.
  </done>
</task>

<task type="auto">
  <name>Task 2: Write docs/METHODOLOGY.md</name>
  <files>docs/METHODOLOGY.md</files>
  <action>
Create docs/METHODOLOGY.md documenting source curation criteria and the query matching algorithm.

**Title:** `# Source Curation Methodology`

**Why Three? section:**
- Explain the design constraint: exactly 3 sources per topic
- Too few (1-2) = no alternatives. Too many (5+) = decision paralysis.
- Three forces prioritization: the best primary source, a practical complement, and an alternative perspective.

**What Makes a Source "Good"? section:**
Document exact criteria:
1. **Authoritative** -- Official docs, primary authors, recognized experts
2. **Current** -- Actively maintained, not abandoned or outdated
3. **Practical** -- Actionable information, not just theory
4. **Accessible** -- Free or freemium, publicly available URLs
5. **Diverse** -- Different source types (doc + tutorial + tool) provide complementary value

**Source Type Taxonomy section:**
List all 10 types: documentation, tutorial, video, article, tool, repo, forum, book, course, api. Brief description of when each is appropriate.

**Ranking Methodology section:**
- Rank 1: Primary official source (almost always official documentation)
- Rank 2: Best practical complement (tutorial, tool, or hands-on resource)
- Rank 3: Community or alternative perspective (forum, article, video)

**Worked Example section (rust-learning):**
Walk through actual rust-learning category from registry.json:
- Show the 3 chosen sources and WHY each was ranked where it is
- Mention 2-3 sources that were REJECTED and why (e.g., "Rustlings is excellent but focuses on exercises not comprehensive learning", "Random blog posts lack authority")
- This provides transparency about the curation process

**Bias Acknowledgment section:**
- Curator has specific domains of expertise (security, bitcoin, maker, self-hosting)
- Sources may reflect those perspectives
- Community contributions can broaden coverage

**Query Matching Algorithm section:**
Document the matching pipeline with technical detail:
1. **Normalization:** lowercase -> strip punctuation -> remove stop words (English, NLTK corpus via stop-words crate) -> normalize whitespace
2. **Fuzzy Scoring:** Normalized Levenshtein distance (strsim crate) against three surfaces: query_patterns (normalized), slug (hyphens replaced with spaces), category name (lowercased). Best match across all surfaces wins.
3. **Keyword Boosting:** Split slug on hyphens, count how many terms appear in the normalized query. Score = matches / total_slug_terms.
4. **Score Combination:** `final = (fuzzy_weight * fuzzy) + (keyword_weight * keyword)`. Default weights: fuzzy 0.7, keyword 0.3.
5. **Threshold Filter:** If best_score < threshold (default 0.4), return error with available categories.

**Adding New Categories section:**
- Create a new entry in registry.json under categories
- Choose a descriptive slug (lowercase, hyphen-separated)
- Write at least 3 query_patterns reflecting natural language queries
- Curate exactly 3 sources following the ranking methodology
- Run the server -- it validates on startup

**Community Contribution Path section:**
- Open issues to suggest new categories or source updates
- PRs welcome with justification for each source choice
- Review cadence: sources checked quarterly for freshness
  </action>
  <verify>
- `test -f docs/METHODOLOGY.md && echo "exists"`
- `grep "Three\|Levenshtein\|threshold\|rust-learning" docs/METHODOLOGY.md` confirms key content
- `grep "Bias\|Rejected\|Adding New" docs/METHODOLOGY.md` confirms transparency sections
- `wc -l docs/METHODOLOGY.md` shows 120+ lines
  </verify>
  <done>
docs/METHODOLOGY.md explains why 3 sources, what makes a source good, the ranking system, a worked example with rejections, the complete matching algorithm, bias acknowledgment, and how to add new categories.
  </done>
</task>

<task type="auto">
  <name>Task 3: Write docs/PUBKY.md</name>
  <files>docs/PUBKY.md</files>
  <action>
Create docs/PUBKY.md documenting PKARR identity, verification, and future federation vision.

**Title:** `# Identity & Verification (PKARR/Pubky)`

**What Is PKARR? section:**
- Brief primer: Public Key Addressable Resource Records
- PKARR enables self-sovereign identity using Ed25519 keypairs
- A PKARR public key is a unique, verifiable identifier for a curator
- No central authority -- the key IS the identity
- Format: z-base-32 encoded public key (52 characters)

**How 3GS Uses PKARR section:**
- On startup, server loads PKARR_SECRET_KEY from environment or generates ephemeral keypair
- Public key is embedded in /health endpoint and get_provenance tool responses
- The key proves: "This server is operated by the holder of this private key"
- Persistent identity requires setting PKARR_SECRET_KEY (64-char hex string)
- Without it, identity changes on every restart (ephemeral mode)

**Verification Guide section (step-by-step with curl):**
Step 1: Get the server's public key
```bash
curl -s http://localhost:3000/health | jq .pubkey
```

Step 2: Call get_provenance to see curator identity
```bash
curl -s -X POST http://localhost:3000/mcp \
  -H "Content-Type: application/json" \
  -d '{"jsonrpc":"2.0","id":1,"method":"initialize","params":{"protocolVersion":"2025-11-25","capabilities":{},"clientInfo":{"name":"curl","version":"1.0"}}}'

curl -s -X POST http://localhost:3000/mcp \
  -H "Content-Type: application/json" \
  -d '{"jsonrpc":"2.0","id":2,"method":"tools/call","params":{"name":"get_provenance","arguments":{}}}' | jq .
```

Step 3: Verify the pubkey from /health matches the one in get_provenance response.

**What This Proves:**
- The server holds the private key corresponding to the advertised public key
- If the same pubkey appears across sessions, it's the same operator
- The pubkey can be shared out-of-band (e.g., on a website) for independent verification

**What Is Pubky? section:**
- Pubky is a broader ecosystem built on PKARR for decentralized web applications
- 3GS v1 uses only the cryptographic primitives (Ed25519 keypair via pkarr crate)
- Future versions may use Pubky homeservers for registry storage

**Future: Federated Trust section:**
- **Endorsements concept:** Other curators can vouch for this registry's quality by signing endorsements with their own PKARR keys
- The get_endorsements tool is scaffolded but returns empty in v1
- Future: Endorsement = {endorser_pubkey, timestamp, signature}
- **Vision:** A network of curators, each with their own registry, endorsing each other. Agents traverse the trust graph to find sources from curators they trust.
- **Not in v1:** Pubky homeserver storage, trust graph traversal, cross-registry queries
  </action>
  <verify>
- `test -f docs/PUBKY.md && echo "exists"`
- `grep "PKARR\|z-base-32\|Ed25519" docs/PUBKY.md` confirms PKARR primer
- `grep "curl\|/health\|get_provenance" docs/PUBKY.md` confirms verification guide
- `grep "endorsement\|federation\|trust" docs/PUBKY.md` confirms future vision
- `wc -l docs/PUBKY.md` shows 80+ lines
  </verify>
  <done>
docs/PUBKY.md explains PKARR basics, how 3GS uses it for identity, provides a step-by-step verification guide with curl commands, and describes the future federated trust vision with endorsements.
  </done>
</task>

</tasks>

<verification>
1. All three files exist: `ls docs/SCHEMA.md docs/METHODOLOGY.md docs/PUBKY.md`
2. Schema covers all types: `grep -c "Category\|Source\|Curator\|Registry" docs/SCHEMA.md`
3. Methodology has worked example: `grep "rust-learning" docs/METHODOLOGY.md`
4. Pubky has curl examples: `grep -c "curl" docs/PUBKY.md`
5. No file is a stub: all files have 80+ lines
</verification>

<success_criteria>
Three deep-dive documentation files provide complete reference material: SCHEMA.md for registry format, METHODOLOGY.md for curation transparency and matching algorithm, and PUBKY.md for identity verification and future vision.
</success_criteria>

<output>
After completion, create `.planning/phases/07-documentation-testing/07-02-SUMMARY.md`
</output>
