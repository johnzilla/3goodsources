---
phase: 07-documentation-testing
plan: 04
type: execute
wave: 2
depends_on: [07-03]
files_modified: [tests/integration_mcp.rs, tests/integration_matching.rs]
autonomous: true

must_haves:
  truths:
    - "MCP protocol tests validate initialize, tools/list, and tools/call JSON-RPC responses"
    - "MCP tests verify malformed JSON returns parse error"
    - "MCP tests verify batch requests are rejected"
    - "MCP tests verify pre-initialization rejection"
    - "Query matching tests confirm 'learn rust' matches rust-learning category"
    - "Query matching tests confirm unrelated queries return no match"
    - "Query matching tests verify empty query handling"
    - "All integration tests pass with cargo test"
  artifacts:
    - path: "tests/integration_mcp.rs"
      provides: "MCP protocol integration tests via real HTTP"
      min_lines: 80
    - path: "tests/integration_matching.rs"
      provides: "Query matching integration tests via real HTTP"
      min_lines: 60
  key_links:
    - from: "tests/integration_mcp.rs"
      to: "tests/common/mod.rs"
      via: "mod common import"
      pattern: "mod common"
    - from: "tests/integration_matching.rs"
      to: "tests/common/mod.rs"
      via: "mod common import"
      pattern: "mod common"
---

<objective>
Implement MCP protocol and query matching integration tests that validate JSON-RPC message formats and query-to-category matching through real HTTP requests.

Purpose: These tests prove the full request flow works end-to-end: HTTP request -> JSON-RPC parsing -> MCP handler -> query matching -> response. They cover TEST-01 (expected matches), TEST-02 (no-match below threshold), and TEST-03 (MCP protocol correctness).

Output: tests/integration_mcp.rs, tests/integration_matching.rs
</objective>

<execution_context>
@/home/john/.claude/get-shit-done/workflows/execute-plan.md
@/home/john/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@.planning/phases/07-documentation-testing/07-03-PLAN.md

@src/mcp/handler.rs
@src/mcp/tools.rs
@src/mcp/types.rs
@src/matcher/scorer.rs
@tests/common/mod.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create MCP protocol integration tests</name>
  <files>tests/integration_mcp.rs</files>
  <action>
Create tests/integration_mcp.rs with tests covering TEST-03 (MCP protocol tests validate all JSON-RPC message formats).

Every test spawns a real HTTP server via common::spawn_test_server() and makes real HTTP POST requests to /mcp with reqwest.

**Helper function:** Create a helper `initialize(client, addr)` that sends the initialize request and returns the response. Many tests need initialization before they can test other methods.

```rust
async fn initialize(client: &reqwest::Client, addr: &std::net::SocketAddr) -> serde_json::Value {
    let response = client
        .post(format!("http://{}/mcp", addr))
        .json(&serde_json::json!({
            "jsonrpc": "2.0",
            "id": 1,
            "method": "initialize",
            "params": {
                "protocolVersion": "2025-11-25",
                "capabilities": {},
                "clientInfo": {"name": "test-client", "version": "1.0"}
            }
        }))
        .send()
        .await
        .unwrap();
    response.json().await.unwrap()
}
```

**Tests to implement:**

1. `test_initialize_returns_protocol_version` -- POST initialize, verify response has jsonrpc "2.0", result.protocolVersion "2025-11-25", result.capabilities.tools is object, result.serverInfo.name is "three-good-sources".

2. `test_tools_list_returns_four_tools` -- Initialize, then POST tools/list. Verify result.tools is array with 4 items. Verify tool names include "get_sources", "list_categories", "get_provenance", "get_endorsements". Verify each tool has name, description, and inputSchema with type "object".

3. `test_tools_call_get_sources` -- Initialize, then POST tools/call with get_sources query "learn rust". Verify result.content is array, result.isError is false, content[0].type is "text", text contains "Rust Learning".

4. `test_tools_call_list_categories` -- Initialize, then call list_categories. Verify isError false, text contains "rust-learning" and "bitcoin-node-setup".

5. `test_tools_call_get_provenance` -- Initialize, then call get_provenance. Verify isError false, text contains "Curator:" and a pubkey.

6. `test_tools_call_get_endorsements` -- Initialize, then call get_endorsements. Verify isError false, text contains "endorsements" or "Endorsements: 0".

7. `test_malformed_json_returns_parse_error` -- POST invalid JSON `"{ invalid }"`. Verify HTTP 200 with error.code -32700 (Parse error). Verify jsonrpc "2.0" in response.

8. `test_batch_request_rejected` -- POST a JSON array. Verify error.code -32600, message contains "Batch".

9. `test_pre_init_tools_list_rejected` -- Without initializing, POST tools/list. Verify error.code -32002.

10. `test_unknown_method_returns_error` -- Initialize, then POST unknown method. Verify error.code -32601.

11. `test_notification_returns_204` -- POST a notification (no id field) for "notifications/initialized". Verify HTTP 204 No Content with empty body.

12. `test_all_responses_have_jsonrpc_field` -- Test multiple request types (parse error, batch, tools/list after init) and verify every response has jsonrpc "2.0".

Each test uses its own spawned server (parallel-safe via port 0). Use `serde_json::json!` macro for request bodies and `serde_json::Value` for response parsing.
  </action>
  <verify>
- `cargo test --test integration_mcp` runs all MCP protocol tests
- All tests pass (exit code 0)
- `grep "#\[tokio::test\]" tests/integration_mcp.rs | wc -l` shows 12 test functions
  </verify>
  <done>
12 MCP protocol integration tests pass, validating initialize handshake, tools/list with 4 tools, tools/call for all 4 tools, malformed JSON handling, batch rejection, pre-init rejection, unknown method error, notification 204 response, and consistent jsonrpc field.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create query matching integration tests</name>
  <files>tests/integration_matching.rs</files>
  <action>
Create tests/integration_matching.rs with tests covering TEST-01 (expected category matches) and TEST-02 (unrelated queries return no match).

Every test spawns a real HTTP server and makes real HTTP POST requests. Each test initializes the MCP handler before making tools/call requests.

**Helper function:** Reuse the same `initialize` helper pattern as in integration_mcp.rs.

**Additional helper:** Create a helper to call get_sources:
```rust
async fn get_sources(client: &reqwest::Client, addr: &std::net::SocketAddr, query: &str) -> serde_json::Value {
    let response = client
        .post(format!("http://{}/mcp", addr))
        .json(&serde_json::json!({
            "jsonrpc": "2.0",
            "id": 2,
            "method": "tools/call",
            "params": {
                "name": "get_sources",
                "arguments": {"query": query}
            }
        }))
        .send()
        .await
        .unwrap();
    response.json().await.unwrap()
}
```

**Tests to implement (TEST-01 -- expected matches):**

1. `test_learn_rust_matches_rust_learning` -- Query "learn rust", verify isError false, text contains "Rust Learning", text contains at least 3 URLs (http).

2. `test_bitcoin_node_matches_bitcoin_node_setup` -- Query "bitcoin node", verify isError false, text contains "Bitcoin Node Setup".

3. `test_email_server_matches_self_hosted_email` -- Query "email server", verify isError false, text contains "Self-Hosted Email".

4. `test_password_manager_matches_password_management` -- Query "password manager", verify isError false, text contains "Password Management".

5. `test_sources_contain_real_urls` -- Query "learn rust", extract text content, verify it contains at least 3 distinct http URLs. This validates real source data is returned, not stub data.

**Tests to implement (TEST-02 -- no match / below threshold):**

6. `test_unrelated_query_returns_no_match` -- Query "quantum physics supercollider", verify isError true, text contains "No matching category" or "Available categories".

7. `test_gibberish_query_returns_no_match` -- Query "xyzzy plugh foobar", verify isError true.

8. `test_empty_query_returns_error` -- Query "", verify isError true, text contains "empty".

**Edge cases:**

9. `test_high_threshold_rejects_partial_match` -- Call get_sources with query "learn rust" AND threshold 0.99. Use custom JSON body with threshold argument. Verify isError true (score won't reach 0.99).

10. `test_each_seed_category_is_matchable` -- For each of the 10 seed categories, query using the category name (e.g., "Rust Learning", "Bitcoin Node Setup"). Verify at least 8 out of 10 return isError false. This ensures the matching algorithm works broadly, not just for cherry-picked queries. Use a loop over category names and count successes.

Each test uses its own server instance for parallelism.
  </action>
  <verify>
- `cargo test --test integration_matching` runs all matching tests
- All tests pass (exit code 0)
- `grep "#\[tokio::test\]" tests/integration_matching.rs | wc -l` shows 10 test functions
- `cargo test` runs ALL tests (inline unit + all integration) and passes
  </verify>
  <done>
10 query matching integration tests pass: 5 expected-match tests verify real category matches with real URLs, 3 no-match tests verify unrelated/empty queries are handled correctly, 1 edge case tests high threshold rejection, and 1 comprehensive test validates all seed categories are matchable.
  </done>
</task>

</tasks>

<verification>
1. `cargo test --test integration_mcp` -- all 12 MCP protocol tests pass
2. `cargo test --test integration_matching` -- all 10 matching tests pass
3. `cargo test` -- full test suite passes (inline units + all 3 integration test files)
4. No test uses mocks or stubs -- all use real registry.json data and real HTTP requests
</verification>

<success_criteria>
Complete integration test suite validates the full request flow: MCP protocol correctness (12 tests covering every JSON-RPC message type), query matching accuracy (5 expected-match tests, 3 no-match tests, 2 edge cases). All tests use real HTTP servers on random ports with real data, zero mocks.
</success_criteria>

<output>
After completion, create `.planning/phases/07-documentation-testing/07-04-SUMMARY.md`
</output>
